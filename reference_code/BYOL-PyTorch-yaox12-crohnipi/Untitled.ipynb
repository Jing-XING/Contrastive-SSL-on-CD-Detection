{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea815e-3c63-41b4-a9a9-4f0154792dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from trainer.byol_trainer import BYOLTrainer\n",
    "from utils import logging_util\n",
    "import os.path\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import apex\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex import amp\n",
    "\n",
    "from model import BYOLModel\n",
    "from optimizer import LARS\n",
    "from data import ImageNetLoader\n",
    "from utils import params_util, logging_util, eval_util\n",
    "from utils.data_prefetcher import data_prefetcher\n",
    "\n",
    "class BYOLTrainer():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.time_stamp = self.config['checkpoint'].get('time_stamp',\n",
    "            datetime.datetime.now().strftime('%m%d_%H-%M'))\n",
    "\n",
    "        \"\"\"device parameters\"\"\"\n",
    "        self.world_size = self.config['world_size']\n",
    "        self.rank = self.config['rank']\n",
    "        self.gpu = self.config['local_rank']\n",
    "        self.distributed = self.config['distributed']\n",
    "\n",
    "        \"\"\"get the train parameters!\"\"\"\n",
    "        self.total_epochs = self.config['optimizer']['total_epochs']\n",
    "        self.warmup_epochs = self.config['optimizer']['warmup_epochs']\n",
    "\n",
    "        self.train_batch_size = self.config['data']['train_batch_size']\n",
    "        self.val_batch_size = self.config['data']['val_batch_size']\n",
    "        self.global_batch_size = self.world_size * self.train_batch_size\n",
    "\n",
    "        self.num_examples = self.config['data']['num_examples']\n",
    "        self.warmup_steps = self.warmup_epochs * self.num_examples // self.global_batch_size\n",
    "        self.total_steps = self.total_epochs * self.num_examples // self.global_batch_size\n",
    "\n",
    "        base_lr = self.config['optimizer']['base_lr'] / 256\n",
    "        self.max_lr = base_lr * self.global_batch_size\n",
    "\n",
    "        self.base_mm = self.config['model']['base_momentum']\n",
    "\n",
    "        \"\"\"construct the whole network\"\"\"\n",
    "        self.resume_path = self.config['checkpoint']['resume_path']\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(f'cuda:{self.gpu}')\n",
    "            torch.cuda.set_device(self.device)\n",
    "            cudnn.benchmark = True\n",
    "            print('using gpu')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            print('using cpu')\n",
    "        self.construct_model()\n",
    "\n",
    "        \"\"\"save checkpoint path\"\"\"\n",
    "        self.save_epoch = self.config['checkpoint']['save_epoch']\n",
    "        self.ckpt_path = self.config['checkpoint']['ckpt_path'].format(\n",
    "            self.time_stamp, self.config['model']['backbone']['type'], {})\n",
    "        if not os.path.exists(self.ckpt_path):\n",
    "            os.makedirs(self.ckpt_path)\n",
    "\n",
    "        \"\"\"log tools in the running phase\"\"\"\n",
    "        self.steps = 0\n",
    "        self.log_step = self.config['log']['log_step']\n",
    "        self.logging = logging_util.get_std_logging()\n",
    "        if self.rank == 0:\n",
    "            self.writer = SummaryWriter(self.config['log']['log_dir'])\n",
    "\n",
    "    def construct_model(self):\n",
    "        \"\"\"get data loader\"\"\"\n",
    "        self.stage = self.config['stage']\n",
    "        assert self.stage == 'train', ValueError(f'Invalid stage: {self.stage}, only \"train\" for BYOL training')\n",
    "        self.data_ins = ImageNetLoader(self.config)\n",
    "        self.train_loader = self.data_ins.get_loader(self.stage, self.train_batch_size)\n",
    "\n",
    "        self.sync_bn = self.config['amp']['sync_bn']\n",
    "        self.opt_level = self.config['amp']['opt_level']\n",
    "        print(f\"sync_bn: {self.sync_bn}\")\n",
    "\n",
    "        \"\"\"build model\"\"\"\n",
    "        print(\"init byol model!\")\n",
    "        net = BYOLModel(self.config)\n",
    "        if self.sync_bn:\n",
    "            net = apex.parallel.convert_syncbn_model(net)\n",
    "        self.model = net.to(self.device)\n",
    "        print(\"init byol model end!\")\n",
    "\n",
    "        \"\"\"build optimizer\"\"\"\n",
    "        print(\"get optimizer!\")\n",
    "        momentum = self.config['optimizer']['momentum']\n",
    "        weight_decay = self.config['optimizer']['weight_decay']\n",
    "        exclude_bias_and_bn = self.config['optimizer']['exclude_bias_and_bn']\n",
    "        params = params_util.collect_params([self.model.online_network, self.model.predictor],\n",
    "                                            exclude_bias_and_bn=exclude_bias_and_bn)\n",
    "        self.optimizer = LARS(params, lr=self.max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "        if self.config['amp']['sync_bn']:\n",
    "            \"\"\"init amp\"\"\"\n",
    "            print(\"amp init!\")\n",
    "            self.model, self.optimizer = amp.initialize(\n",
    "                self.model, self.optimizer, opt_level=self.opt_level)\n",
    "\n",
    "            if self.distributed:\n",
    "                self.model = DDP(self.model, delay_allreduce=True)\n",
    "            print(\"amp init end!\")\n",
    "\n",
    "    # resume snapshots from pre-train\n",
    "    def resume_model(self, model_path=None):\n",
    "        if model_path is None and not self.resume_path:\n",
    "            self.start_epoch = 0\n",
    "            self.logging.info(\"--> No loaded checkpoint!\")\n",
    "        else:\n",
    "            model_path = model_path or self.resume_path\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "\n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.steps = checkpoint['steps']\n",
    "            self.model.load_state_dict(checkpoint['model'], strict=True)\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            amp.load_state_dict(checkpoint['amp'])\n",
    "            self.logging.info(f\"--> Loaded checkpoint '{model_path}' (epoch {self.start_epoch})\")\n",
    "\n",
    "    # save snapshots\n",
    "    def save_checkpoint(self, epoch):\n",
    "        if epoch % self.save_epoch == 0 and self.rank == 0:\n",
    "            state = {'config': self.config,\n",
    "                     'epoch': epoch,\n",
    "                     'steps': self.steps,\n",
    "                     'model': self.model.state_dict(),\n",
    "                     'optimizer': self.optimizer.state_dict(),\n",
    "                     #'amp': amp.state_dict()\n",
    "                    }\n",
    "            torch.save(state, self.ckpt_path.format(epoch))\n",
    "\n",
    "    def adjust_learning_rate(self, step):\n",
    "        \"\"\"learning rate warm up and decay\"\"\"\n",
    "        max_lr = self.max_lr\n",
    "        min_lr = 1e-3 * self.max_lr\n",
    "        if step < self.warmup_steps:\n",
    "            lr = (max_lr - min_lr) * step / self.warmup_steps + min_lr\n",
    "        else:\n",
    "            lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + np.cos((step - self.warmup_steps) * np.pi / self.total_steps))\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def adjust_mm(self, step):\n",
    "        self.mm = 1 - (1 - self.base_mm) * (np.cos(np.pi * step / self.total_steps) + 1) / 2\n",
    "\n",
    "    def forward_loss(self, preds, targets):\n",
    "        bz = preds.size(0)\n",
    "        preds_norm = F.normalize(preds, dim=1)\n",
    "        targets_norm = F.normalize(targets, dim=1)\n",
    "        loss = 2 - 2 * (preds_norm * targets_norm).sum() / bz\n",
    "        return loss\n",
    "\n",
    "    def train_epoch(self, epoch, printer=print):\n",
    "        batch_time = eval_util.AverageMeter()\n",
    "        data_time = eval_util.AverageMeter()\n",
    "        forward_time = eval_util.AverageMeter()\n",
    "        backward_time = eval_util.AverageMeter()\n",
    "        log_time = eval_util.AverageMeter()\n",
    "        loss_meter = eval_util.AverageMeter()\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        end = time.time()\n",
    "        self.data_ins.set_epoch(epoch)\n",
    "\n",
    "        prefetcher = data_prefetcher(self.train_loader)\n",
    "        images, _ = prefetcher.next()\n",
    "        i = 0\n",
    "        while images is not None:\n",
    "            i += 1\n",
    "            self.adjust_learning_rate(self.steps)\n",
    "            self.adjust_mm(self.steps)\n",
    "            self.steps += 1\n",
    "\n",
    "            assert images.dim() == 5, f\"Input must have 5 dims, got: {images.dim()}\"\n",
    "            view1 = images[:, 0, ...].contiguous()\n",
    "            view2 = images[:, 1, ...].contiguous()\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            # forward\n",
    "            tflag = time.time()\n",
    "            q, target_z = self.model(view1, view2, self.mm)\n",
    "            forward_time.update(time.time() - tflag)\n",
    "\n",
    "            tflag = time.time()\n",
    "            loss = self.forward_loss(q, target_z)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            if self.opt_level == 'O0':\n",
    "                loss.backward()\n",
    "            else:\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            backward_time.update(time.time() - tflag)\n",
    "            loss_meter.update(loss.item(), view1.size(0))\n",
    "\n",
    "            tflag = time.time()\n",
    "            if self.steps % self.log_step == 0 and self.rank == 0:\n",
    "                self.writer.add_scalar('lr', round(self.optimizer.param_groups[0]['lr'], 5), self.steps)\n",
    "                self.writer.add_scalar('mm', round(self.mm, 5), self.steps)\n",
    "                self.writer.add_scalar('loss', loss_meter.val, self.steps)\n",
    "            log_time.update(time.time() - tflag)\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # Print log info\n",
    "            if self.gpu == 0 and self.steps % self.log_step == 0:\n",
    "                printer(f'Epoch: [{epoch}][{i}/{len(self.train_loader)}]\\t'\n",
    "                        f'Step {self.steps}\\t'\n",
    "                        f'lr {round(self.optimizer.param_groups[0][\"lr\"], 5)}\\t'\n",
    "                        f'mm {round(self.mm, 5)}\\t'\n",
    "                        f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "                        f'Batch Time {batch_time.val:.4f} ({batch_time.avg:.4f})\\t'\n",
    "                        f'Data Time {data_time.val:.4f} ({data_time.avg:.4f})\\t'\n",
    "                        f'Forward Time {forward_time.val:.4f} ({forward_time.avg:.4f})\\t'\n",
    "                        f'Backward Time {backward_time.val:.4f} ({backward_time.avg:.4f})\\t'\n",
    "                        f'Log Time {log_time.val:.4f} ({log_time.avg:.4f})\\t')\n",
    "\n",
    "            images, _ = prefetcher.next()\n",
    "\n",
    "def run_task(config):\n",
    "    logging = logging_util.get_std_logging()\n",
    "    if config['distributed']:\n",
    "        world_size = int(os.environ['WORLD_SIZE'])\n",
    "        rank = int(os.environ['RANK'])\n",
    "        local_rank = int(os.environ.get('LOCAL_RANK', '0'))\n",
    "        config.update({'world_size': world_size, 'rank': rank, 'local_rank': local_rank})\n",
    "\n",
    "        dist.init_process_group(backend=\"nccl\", world_size=world_size, rank=rank)\n",
    "        logging.info(f'world_size {world_size}, gpu {local_rank}, rank {rank} init done.')\n",
    "    else:\n",
    "        config.update({'world_size': 1, 'rank': 0, 'local_rank': 0})\n",
    "\n",
    "    trainer = BYOLTrainer(config)\n",
    "    trainer.resume_model()\n",
    "    start_epoch = trainer.start_epoch\n",
    "\n",
    "    for epoch in range(start_epoch + 1, trainer.total_epochs + 1):\n",
    "        trainer.train_epoch(epoch, printer=logging.info)\n",
    "        trainer.save_checkpoint(epoch)\n",
    "\n",
    "def main():\n",
    "    run_task(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f'Pytorch version: {torch.__version__}')\n",
    "    print(f'os environ: {os.environ}')\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ead6e-3c81-4716-98f1-0d68acd7e7f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44271dd-847c-4a99-b014-9b2a17aed1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
